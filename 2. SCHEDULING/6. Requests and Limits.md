Los **Limits** son la cantidad máxima que un recurso puede utilizar por un contenedor. Esto significa que el contenedor nunca va a poder consumir más que la memoria y CPU indicada.
Los **Requests** son la mínima cantidad de recursos reservada para un contenedor. 

---

En la sección de limits y request, tenemos la memoria asignada y la ocupada respectivamente. Normalmente se superan en memoria y es un error común, el pod se reinicia si ha sido un pico de memoria. Sino puede ser un error de una actualización del software del pod o un incremento sustancial en el número de clientes de este.

**IMPORTANTE** porque muchas veces es una causa de fallo sobreexceder la memoria asignada por el scheduler. 

Si sobreexcede la memoria asignada, queda en estado out-of-memory-kill y se reiniciaría el contenedor. El límite se puede definir tanto a nivel de pod como de contenedor. 

``kubectl top pod (nombrepod) -n namespace`` nos muestra qué memoria está usando el pod directamente. Es una herramienta externa a kubectl, hay que instalarla. 

---

### Limitar uso de recursos a nivel de NameSpace

Existen dos mecanismos para limitar el uso de los recursos dentro de un ns. 
- LimitRange: permite especificar el uso para los Pods y los contenedores que tenemos dentro de un namespace. Esto impide que los pods o contenedores no superen determinados límites dentro de un entorno.
- ResourceQuota: este componente permite limitar los recursos totales utilizados dentro de un namespace. Esto permite que múltiples proyectos en nuestra infrastructura que consuman distintos límites de recursos. 


LimitRange no aplica a los recursos ya desplegados. Si queremos que se aplique la configuración establecida, deberemos volver a crear el recurso. 


#### LimitRange

```
apiVersion: v1
kind: LimitRange
metadata:
  name: recursos
spec:
  limits:
  - default:
      memory: 512Mi
      cpu: 1
    defaultRequest:
      memory: 256Mi
      cpu: 0.5
    max:
      memory: 1Gi
      cpu: 4
    min:
      memory: 128Mi
      cpu: 0.5
    type: Container

```

En este ejemplo, determinamos cierta capacidad por defecto para todo el namespace, y también le podemos establecer un mínimo y un máximo de recursos. 

El tipo puede ser a nivel de contenedor o de pod. A nivel de pod tiene sentido si tenemos varios contenedores dentro de un pod, donde determinaremos los recursos totales que compartiran x contenedores.

Si no indicamos el valor de request y si el de limits, intentará igualarlo. Puede ser bueno, pero dejas de tener un intervalo de recursos. 

#### ResourceQuota

Las quotas se establecen a nivel de namespace completo. Impide que un namespace supere ciertos límites a nivel global. 

```
apiVersion: v1
kind: ResourceQuota
metadata:
  name: pods-grandes
spec:
  hard:
    cpu: "100"
    memory: 500Mi
    pods: "5"
```

``kubectl get quota`` nos muestra la quota que hemos creado.

Si no indicamos si es request o limit, lo interpreta directamente como request.
Se pueden especificar mediante: "limits.cpu", "limits.memory" y sus análogos con request. 

Si intentamos crear un pod ahora, nos saltará un error si no indicamos los request y limits necesarios para satisfacer dichas quotas. 

##### TRABAJAR CON MÚLTIPLES QUOTAS

Con el ScopeSelector sirve para detectar una clase de prioridad, que debe existir previamente, que determinará si un pod va a una quota o a otra quota. 
Si seguimos el ejemplo anterior [[Prioridad. priorityClassName]] (Ejemplo). 

Se asigna una quota a un pod de forma muy sencilla. En el spec se define 
``priorityClassName: <nomb_pc>``  


